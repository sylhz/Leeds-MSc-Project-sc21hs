{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "import os\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'valid_bs': 32,\n",
    "    'num_workers': 4,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 3,\n",
    "    'used_epochs': [5,5,5,5,5],\n",
    "    'weights': [1,1,1,1]\n",
    "}\n",
    "submission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    img_bgr = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "img = get_img('../input/cassava-leaf-disease-classification/train_images/1000015157.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            df,\n",
    "            data_root,\n",
    "            transforms=None,\n",
    "            output_label=True,\n",
    "            one_hot_label=False,\n",
    "            do_fmix=False,\n",
    "            fmix_params={\n",
    "                'alpha': 1.,\n",
    "                'decay_power': 3.,\n",
    "                'shape': (512, 512),\n",
    "                'max_soft': 0.3,\n",
    "                'reformulate': False\n",
    "            },\n",
    "            do_cutmix=False,\n",
    "            cutmix_params={\n",
    "                'alpha': 1,\n",
    "            }):\n",
    "\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()  \n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.do_fmix = do_fmix\n",
    "        self.fmix_params = fmix_params\n",
    "        self.do_cutmix = do_cutmix\n",
    "        self.cutmix_params = cutmix_params\n",
    "        self.output_label = output_label\n",
    "        self.one_hot_label = one_hot_label\n",
    "        if output_label:\n",
    "            self.labels = self.df['label'].values\n",
    "            if one_hot_label:\n",
    "                self.labels = np.eye(self.df['label'].max() +\n",
    "                                     1)[self.labels] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Args:\n",
    "            index : int , 索引\n",
    "        Returns:\n",
    "            img, target(optional)\n",
    "        '''\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "\n",
    "        img = get_img(\n",
    "            os.path.join(self.data_root,\n",
    "                         self.df.loc[index]['image_id']))  \n",
    "\n",
    "        if self.transforms:  \n",
    "            img = self.transforms(image=img)['image']\n",
    "\n",
    "        if self.do_fmix and np.random.uniform(\n",
    "                0., 1., size=1)[0] > 0.5:  \n",
    "\n",
    "            with torch.no_grad():\n",
    "                lam, mask = sample_mask(\n",
    "                    **self.fmix_params)  \n",
    "\n",
    "                fmix_ix = np.random.choice(self.df.index,\n",
    "                                           size=1)[0]  \n",
    "                fmix_img = get_img(\n",
    "                    os.path.join(self.data_root,\n",
    "                                 self.df.loc[fmix_ix]['image_id']))\n",
    "\n",
    "                if self.transforms:\n",
    "                    fmix_img = self.transforms(image=fmix_img)['image']\n",
    "\n",
    "                mask_torch = torch.from_numpy(mask)\n",
    "\n",
    "                img = mask_torch * img + (1. - mask_torch) * fmix_img \n",
    "\n",
    "                rate = mask.sum() / float(img.size)  \n",
    "                target = rate * target + (\n",
    "                    1. - rate) * self.labels[fmix_ix]  \n",
    "\n",
    "        if self.do_cutmix and np.random.uniform(\n",
    "                0., 1., size=1)[0] > 0.5:  \n",
    "            with torch.no_grad():\n",
    "                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                cmix_img = get_img(\n",
    "                    os.path.join(self.data_root,\n",
    "                                 self.df.loc[cmix_ix]['image_id']))\n",
    "                if self.transforms:\n",
    "                    cmix_img = self.transforms(image=cmix_img)['image']\n",
    "\n",
    "                lam = np.clip(\n",
    "                    np.random.beta(self.cutmix_params['alpha'],\n",
    "                                   self.cutmix_params['alpha']), 0.3, 0.4)\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(cmix_img.shape[:2], lam)\n",
    "\n",
    "                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2,\n",
    "                                                        bby1:bby2]\n",
    "\n",
    "                rate = 1 - ((bbx2 - bbx1) *\n",
    "                            (bby2 - bby1) / float(img.size))  \n",
    "                target = rate * target + (\n",
    "                    1. - rate) * self.labels[cmix_ix]  \n",
    "\n",
    "        if self.output_label:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_transforms():\n",
    "    '''Data Augmentation TTA use in testing phase\n",
    "    '''\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    print(pbar)\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_preds = model(imgs) \n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image_id'] = list(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))\n",
    "test_ds = CassavaDataset(test, '../input/cassava-leaf-disease-classification/test_images/', transforms=get_inference_transforms(), output_label=False)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "            test_ds, \n",
    "            batch_size=CFG['valid_bs'],\n",
    "            num_workers=CFG['num_workers'],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "device = torch.device(CFG['device'])\n",
    "model = CassvaImgClassifier(CFG['model_arch'], 5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = []\n",
    "tst_preds = []\n",
    "\n",
    "# Select the best epoch result in the model for each fold, and do 3 tta fusions to get the final result.\n",
    "for fold, epoch in enumerate(CFG['used_epochs']):    \n",
    "    model.load_state_dict(torch.load('../input/{}-fold-{}-{}/{}_fold_{}_{}'.format('-'.join(CFG['model_arch'].split('_')), fold, epoch,CFG['model_arch'], fold, epoch)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(CFG['tta']):\n",
    "            tst_preds += [CFG['weights'][fold]/sum(CFG['weights'])/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n",
    "\n",
    "tst_preds = np.sum(tst_preds, axis=0) \n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = np.argmax(tst_preds, axis=1)\n",
    "test.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
