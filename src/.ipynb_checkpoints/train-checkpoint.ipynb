{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入依赖的库\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import utils\n",
    "from imp import reload\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
    "    ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "reload(utils)\n",
    "rand_seed = 666\n",
    "utils.seed_everything(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = r'../data/train_images' #样本图片的路径\n",
    "train_csv_path = r'../data/train.csv' #训练集合标记CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集数据增强\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "        Transpose(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        VerticalFlip(p=0.5),\n",
    "        ShiftScaleRotate(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        CoarseDropout(p=0.5),\n",
    "        Cutout(p=0.5),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)\n",
    "\n",
    "# 验证集数据增强\n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "        CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "        Resize(CFG['img_size'], CFG['img_size']),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型构建\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据\n",
    "CFG = {\n",
    "    'img_size' : 512,\n",
    "    'epochs': 15,\n",
    "    'fold_num': 5,\n",
    "    'device': 'cpu',\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'train_bs' : 2,\n",
    "    'valid_bs' : 2,\n",
    "    'num_workers' : 0,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6,\n",
    "    'T_0': 10,\n",
    "    'min_lr': 1e-6,\n",
    "}\n",
    "train = pd.read_csv(train_csv_path)\n",
    "folds = StratifiedKFold(n_splits=CFG['fold_num'],\n",
    "                        shuffle=True,\n",
    "                        random_state=rand_seed).split(\n",
    "                            np.arange(train.shape[0]), train.label.values)\n",
    "trn_transform = get_train_transforms()\n",
    "val_transform = get_valid_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "Train : 17117, Val : 4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8559 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/torch/cuda/amp/autocast_mode.py:114: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "\n",
      "\n",
      "\n",
      "epoch 0 loss: 1.6059:   0%|          | 0/8559 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "epoch 0 loss: 1.6059:   0%|          | 1/8559 [00:07<18:46:41,  7.90s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "epoch 0 loss: 1.6060:   0%|          | 1/8559 [00:14<18:46:41,  7.90s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "epoch 0 loss: 1.6060:   0%|          | 2/8559 [00:14<17:35:07,  7.40s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-5cc2ef3384d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                 \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                 \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                 schd_batch_update=False)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/比赛训练营/Kaggle木薯叶比赛/代码/code/src/utils/utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loss_fn, optimizer, train_loader, device, scaler, scheduler, schd_batch_update, accum_iter)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 计算 loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 对 loss scale, scale梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# loss 正则,使用指数平均\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold_num = 0\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    if fold == fold_num:\n",
    "        print('Training with {} started'.format(fold))\n",
    "        print('Train : {}, Val : {}'.format(len(trn_idx), len(val_idx)))\n",
    "        train_loader, val_loader = utils.prepare_dataloader(train,\n",
    "                                                          trn_idx,\n",
    "                                                          val_idx,\n",
    "                                                          data_root = train_img_path,\n",
    "                                                          trn_transform = trn_transform,\n",
    "                                                          val_transform = val_transform, \n",
    "                                                          bs = CFG['train_bs'], \n",
    "                                                          n_job = CFG['num_workers'])\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "\n",
    "        model = CassvaImgClassifier(CFG['model_arch'],\n",
    "                                    train.label.nunique(),\n",
    "                                    pretrained=True).to(device)\n",
    "        scaler = GradScaler()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=CFG['lr'],\n",
    "                                     weight_decay=CFG['weight_decay'])\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=CFG['T_0'],\n",
    "            T_mult=1,\n",
    "            eta_min=CFG['min_lr'],\n",
    "            last_epoch=-1)\n",
    "\n",
    "        loss_tr = nn.CrossEntropyLoss().to(\n",
    "            device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            utils.train_one_epoch(epoch,\n",
    "                                model,\n",
    "                                loss_tr,\n",
    "                                optimizer,\n",
    "                                train_loader,\n",
    "                                device,\n",
    "                                scaler,\n",
    "                                scheduler=scheduler,\n",
    "                                schd_batch_update=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                utils.valid_one_epoch(epoch,\n",
    "                                    model,\n",
    "                                    loss_fn,\n",
    "                                    val_loader,\n",
    "                                    device)\n",
    "\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                '../model/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
    "\n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
