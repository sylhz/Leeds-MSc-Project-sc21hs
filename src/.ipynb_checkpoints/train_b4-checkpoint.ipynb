{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependent libraries\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import utils\n",
    "from imp import reload\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
    "    ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "reload(utils)\n",
    "rand_seed = 666\n",
    "utils.seed_everything(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting timm\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/72/ed/358a8bc5685c31c0fe7765351b202cf6a8c087893b5d2d64f63c950f8beb/timm-0.6.7-py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 67.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /environment/miniconda3/lib/python3.7/site-packages (from timm) (0.11.1+cu113)\n",
      "Requirement already satisfied: torch>=1.4 in /environment/miniconda3/lib/python3.7/site-packages (from timm) (1.10.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /environment/miniconda3/lib/python3.7/site-packages (from torch>=1.4->timm) (4.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /environment/miniconda3/lib/python3.7/site-packages (from torchvision->timm) (8.4.0)\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.7/site-packages (from torchvision->timm) (1.21.4)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.6.7\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = '/home/featurize/data/train_images'  \n",
    "train_csv_path = '/home/featurize/data/train.csv'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/data/train.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set data augmentation\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "        Transpose(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        VerticalFlip(p=0.5),\n",
    "        ShiftScaleRotate(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        CoarseDropout(p=0.5),\n",
    "        Cutout(p=0.5),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)\n",
    "\n",
    "# Validation set data augmentation\n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "        CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "        Resize(CFG['img_size'], CFG['img_size']),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 6.19G/6.19G [00:21<00:00, 285MiB/s]\n",
      "🍬  下载完成，正在解压...\n",
      "🏁  数据集已经成功添加\n"
     ]
    }
   ],
   "source": [
    "!featurize dataset download 17bd6643-4e22-423b-95c7-3f82601931bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# build data\n",
    "CFG = {\n",
    "    'img_size' : 512,\n",
    "    'epochs': 10,\n",
    "    'fold_num': 5,\n",
    "    'device': 'cuda',\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'train_bs' : 16,\n",
    "    'valid_bs' : 16,\n",
    "    'num_workers' : 0,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6,\n",
    "    'T_0': 10,\n",
    "    'min_lr': 1e-6,\n",
    "}\n",
    "train = pd.read_csv(train_csv_path)\n",
    "folds = StratifiedKFold(n_splits=CFG['fold_num'],\n",
    "                        shuffle=True,\n",
    "                        random_state=rand_seed).split(\n",
    "                            np.arange(train.shape[0]), train.label.values)\n",
    "trn_transform = get_train_transforms()\n",
    "val_transform = get_valid_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    print(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "Train : 17117, Val : 4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b4_ns-d6313a46.pth\" to /home/featurize/.cache/torch/hub/checkpoints/tf_efficientnet_b4_ns-d6313a46.pth\n",
      "epoch 0 loss: 0.4952: 100%|██████████| 1070/1070 [14:09<00:00,  1.26it/s]\n",
      "epoch 0 loss: 0.3786: 100%|██████████| 268/268 [01:35<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.4104: 100%|██████████| 1070/1070 [14:09<00:00,  1.26it/s]\n",
      "epoch 1 loss: 0.3321: 100%|██████████| 268/268 [01:34<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3973: 100%|██████████| 1070/1070 [14:02<00:00,  1.27it/s]\n",
      "epoch 2 loss: 0.3360: 100%|██████████| 268/268 [01:33<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3529: 100%|██████████| 1070/1070 [13:51<00:00,  1.29it/s]\n",
      "epoch 3 loss: 0.3343: 100%|██████████| 268/268 [01:34<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3277: 100%|██████████| 1070/1070 [13:57<00:00,  1.28it/s]\n",
      "epoch 4 loss: 0.3193: 100%|██████████| 268/268 [01:33<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3154: 100%|██████████| 1070/1070 [14:00<00:00,  1.27it/s]\n",
      "epoch 5 loss: 0.3249: 100%|██████████| 268/268 [01:34<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.2908: 100%|██████████| 1070/1070 [13:56<00:00,  1.28it/s]\n",
      "epoch 6 loss: 0.3241: 100%|██████████| 268/268 [01:33<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2794: 100%|██████████| 1070/1070 [13:56<00:00,  1.28it/s]\n",
      "epoch 7 loss: 0.3294: 100%|██████████| 268/268 [01:33<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2775: 100%|██████████| 1070/1070 [13:49<00:00,  1.29it/s]\n",
      "epoch 8 loss: 0.3351: 100%|██████████| 268/268 [01:33<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2682: 100%|██████████| 1070/1070 [13:53<00:00,  1.28it/s]\n",
      "epoch 9 loss: 0.3356: 100%|██████████| 268/268 [01:34<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8848\n",
      "Training with 1 started\n",
      "Train : 17118, Val : 4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4601: 100%|██████████| 1070/1070 [13:23<00:00,  1.33it/s]\n",
      "epoch 0 loss: 0.3737: 100%|██████████| 268/268 [01:28<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.3999: 100%|██████████| 1070/1070 [13:18<00:00,  1.34it/s]\n",
      "epoch 1 loss: 0.3680: 100%|██████████| 268/268 [01:26<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3840: 100%|██████████| 1070/1070 [13:13<00:00,  1.35it/s]\n",
      "epoch 2 loss: 0.3299: 100%|██████████| 268/268 [01:27<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3590: 100%|██████████| 1070/1070 [13:26<00:00,  1.33it/s]\n",
      "epoch 3 loss: 0.3293: 100%|██████████| 268/268 [01:26<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3467: 100%|██████████| 1070/1070 [13:20<00:00,  1.34it/s]\n",
      "epoch 4 loss: 0.3339: 100%|██████████| 268/268 [01:27<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.2928: 100%|██████████| 1070/1070 [13:13<00:00,  1.35it/s]\n",
      "epoch 5 loss: 0.3197: 100%|██████████| 268/268 [01:27<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.3013: 100%|██████████| 1070/1070 [13:18<00:00,  1.34it/s]\n",
      "epoch 6 loss: 0.3241: 100%|██████████| 268/268 [01:31<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2802: 100%|██████████| 1070/1070 [13:11<00:00,  1.35it/s]\n",
      "epoch 7 loss: 0.3323: 100%|██████████| 268/268 [01:26<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.3290: 100%|██████████| 268/268 [01:27<00:00,  3.06it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2651: 100%|██████████| 1070/1070 [13:22<00:00,  1.33it/s]\n",
      "epoch 9 loss: 0.3362: 100%|██████████| 268/268 [01:27<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8932\n",
      "Training with 2 started\n",
      "Train : 17118, Val : 4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4903: 100%|██████████| 1070/1070 [13:58<00:00,  1.28it/s]\n",
      "epoch 0 loss: 0.3718: 100%|██████████| 268/268 [01:33<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.3923: 100%|██████████| 1070/1070 [13:49<00:00,  1.29it/s]\n",
      "epoch 1 loss: 0.3565: 100%|██████████| 268/268 [01:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3549: 100%|██████████| 1070/1070 [14:06<00:00,  1.26it/s]\n",
      "epoch 2 loss: 0.3313: 100%|██████████| 268/268 [01:36<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3668: 100%|██████████| 1070/1070 [13:46<00:00,  1.30it/s]\n",
      "epoch 3 loss: 0.3349: 100%|██████████| 268/268 [01:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3378: 100%|██████████| 1070/1070 [14:08<00:00,  1.26it/s]\n",
      "epoch 4 loss: 0.3266: 100%|██████████| 268/268 [01:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3292: 100%|██████████| 1070/1070 [13:52<00:00,  1.29it/s]\n",
      "epoch 5 loss: 0.3281: 100%|██████████| 268/268 [01:34<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.2935: 100%|██████████| 1070/1070 [14:06<00:00,  1.26it/s]\n",
      "epoch 6 loss: 0.3248: 100%|██████████| 268/268 [01:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2693: 100%|██████████| 1070/1070 [14:10<00:00,  1.26it/s]\n",
      "epoch 7 loss: 0.3296: 100%|██████████| 268/268 [01:33<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2628: 100%|██████████| 1070/1070 [13:52<00:00,  1.28it/s]\n",
      "epoch 8 loss: 0.3310: 100%|██████████| 268/268 [01:34<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2667: 100%|██████████| 1070/1070 [13:54<00:00,  1.28it/s]\n",
      "epoch 9 loss: 0.3291: 100%|██████████| 268/268 [01:33<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8878\n",
      "Training with 3 started\n",
      "Train : 17118, Val : 4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4726: 100%|██████████| 1070/1070 [13:49<00:00,  1.29it/s]\n",
      "epoch 0 loss: 0.4085: 100%|██████████| 268/268 [01:34<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.4116: 100%|██████████| 1070/1070 [13:47<00:00,  1.29it/s]\n",
      "epoch 1 loss: 0.3637: 100%|██████████| 268/268 [01:33<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3842: 100%|██████████| 1070/1070 [13:58<00:00,  1.28it/s]\n",
      "epoch 2 loss: 0.3593: 100%|██████████| 268/268 [01:33<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3573: 100%|██████████| 1070/1070 [13:52<00:00,  1.29it/s]\n",
      "epoch 3 loss: 0.3573: 100%|██████████| 268/268 [01:35<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3460: 100%|██████████| 1070/1070 [13:53<00:00,  1.28it/s]\n",
      "epoch 4 loss: 0.3608: 100%|██████████| 268/268 [01:34<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3103: 100%|██████████| 1070/1070 [13:59<00:00,  1.27it/s]\n",
      "epoch 5 loss: 0.3394: 100%|██████████| 268/268 [01:34<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.3013: 100%|██████████| 1070/1070 [13:59<00:00,  1.27it/s]\n",
      "epoch 6 loss: 0.3528: 100%|██████████| 268/268 [01:34<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2578: 100%|██████████| 1070/1070 [13:56<00:00,  1.28it/s]\n",
      "epoch 7 loss: 0.3587: 100%|██████████| 268/268 [01:33<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2732: 100%|██████████| 1070/1070 [13:56<00:00,  1.28it/s]\n",
      "epoch 8 loss: 0.3577: 100%|██████████| 268/268 [01:35<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2688: 100%|██████████| 1070/1070 [13:56<00:00,  1.28it/s]\n",
      "epoch 9 loss: 0.3611: 100%|██████████| 268/268 [01:35<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8806\n"
     ]
    }
   ],
   "source": [
    "fold_num = 0\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    print('Training with {} started'.format(fold))\n",
    "    print('Train : {}, Val : {}'.format(len(trn_idx), len(val_idx)))\n",
    "    train_loader, val_loader = utils.prepare_dataloader(train,\n",
    "                                                        trn_idx,\n",
    "                                                        val_idx,\n",
    "                                                        data_root = train_img_path,\n",
    "                                                        trn_transform = trn_transform,\n",
    "                                                        val_transform = val_transform, \n",
    "                                                        bs = CFG['train_bs'], \n",
    "                                                        n_job = CFG['num_workers'])\n",
    "\n",
    "    device = torch.device(CFG['device'])\n",
    "\n",
    "    model = CassvaImgClassifier(CFG['model_arch'],\n",
    "                                train.label.nunique(),\n",
    "                                pretrained=True).to(device)\n",
    "    scaler = GradScaler()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                    lr=CFG['lr'],\n",
    "                                    weight_decay=CFG['weight_decay'])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=CFG['T_0'],\n",
    "        T_mult=1,\n",
    "        eta_min=CFG['min_lr'],\n",
    "        last_epoch=-1)\n",
    "\n",
    "    loss_tr = nn.CrossEntropyLoss().to(\n",
    "        device)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        utils.train_one_epoch(epoch,\n",
    "                            model,\n",
    "                            loss_tr,\n",
    "                            optimizer,\n",
    "                            train_loader,\n",
    "                            device,\n",
    "                            scaler,\n",
    "                            scheduler=scheduler,\n",
    "                            schd_batch_update=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            utils.valid_one_epoch(epoch,\n",
    "                                model,\n",
    "                                loss_fn,\n",
    "                                val_loader,\n",
    "                                device)\n",
    "\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            '/home/featurize/work/model/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
    "\n",
    "    del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
