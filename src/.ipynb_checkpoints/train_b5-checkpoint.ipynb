{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependent libraries\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import utils\n",
    "from imp import reload\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
    "    ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "reload(utils)\n",
    "rand_seed = 666\n",
    "utils.seed_everything(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: timm in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (0.6.7)\n",
      "Requirement already satisfied: torch>=1.4 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from timm) (1.12.0)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from timm) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from torch>=1.4->timm) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\11055\\appdata\\roaming\\python\\python37\\site-packages (from torchvision->timm) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from torchvision->timm) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from requests->torchvision->timm) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from requests->torchvision->timm) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from requests->torchvision->timm) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from requests->torchvision->timm) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = '/home/featurize/data/train_images'  \n",
    "train_csv_path = '/home/featurize/data/train.csv'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/data/train.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set data augmentation\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "        Transpose(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        VerticalFlip(p=0.5),\n",
    "        ShiftScaleRotate(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        CoarseDropout(p=0.5),\n",
    "        Cutout(p=0.5),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)\n",
    "\n",
    "# Validation set data augmentation\n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "        CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "        Resize(CFG['img_size'], CFG['img_size']),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# build data\n",
    "CFG = {\n",
    "    'img_size' : 512,\n",
    "    'epochs': 10,\n",
    "    'fold_num': 5,\n",
    "    'device': 'cuda',\n",
    "    'model_arch': 'tf_efficientnet_b5_ns',\n",
    "    'train_bs' : 16,\n",
    "    'valid_bs' : 16,\n",
    "    'num_workers' : 0,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6,\n",
    "    'T_0': 10,\n",
    "    'min_lr': 1e-6,\n",
    "}\n",
    "train = pd.read_csv(train_csv_path)\n",
    "folds = StratifiedKFold(n_splits=CFG['fold_num'],\n",
    "                        shuffle=True,\n",
    "                        random_state=rand_seed).split(\n",
    "                            np.arange(train.shape[0]), train.label.values)\n",
    "trn_transform = get_train_transforms()\n",
    "val_transform = get_valid_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "Train : 17117, Val : 4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4390: 100%|██████████| 1070/1070 [17:56<00:00,  1.01s/it]\n",
      "epoch 0 loss: 0.4059: 100%|██████████| 268/268 [01:55<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.3794: 100%|██████████| 1070/1070 [17:59<00:00,  1.01s/it]\n",
      "epoch 1 loss: 0.3521: 100%|██████████| 268/268 [01:50<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3587: 100%|██████████| 1070/1070 [18:09<00:00,  1.02s/it]\n",
      "epoch 2 loss: 0.3729: 100%|██████████| 268/268 [01:49<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3605: 100%|██████████| 1070/1070 [18:24<00:00,  1.03s/it]\n",
      "epoch 3 loss: 0.3351: 100%|██████████| 268/268 [01:48<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3025: 100%|██████████| 1070/1070 [17:54<00:00,  1.00s/it]\n",
      "epoch 4 loss: 0.3435: 100%|██████████| 268/268 [01:46<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3029: 100%|██████████| 1070/1070 [18:06<00:00,  1.02s/it]\n",
      "epoch 5 loss: 0.3391: 100%|██████████| 268/268 [01:46<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.2642: 100%|██████████| 1070/1070 [18:01<00:00,  1.01s/it]\n",
      "epoch 6 loss: 0.3432: 100%|██████████| 268/268 [01:47<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2498: 100%|██████████| 1070/1070 [17:51<00:00,  1.00s/it]\n",
      "epoch 7 loss: 0.3565: 100%|██████████| 268/268 [01:45<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2315: 100%|██████████| 1070/1070 [18:02<00:00,  1.01s/it]\n",
      "epoch 8 loss: 0.3732: 100%|██████████| 268/268 [01:46<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2257: 100%|██████████| 1070/1070 [17:59<00:00,  1.01s/it]\n",
      "epoch 9 loss: 0.3781: 100%|██████████| 268/268 [01:45<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8808\n",
      "Training with 1 started\n",
      "Train : 17117, Val : 4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4551: 100%|██████████| 1070/1070 [17:18<00:00,  1.03it/s]\n",
      "epoch 0 loss: 0.3728: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.4157: 100%|██████████| 1070/1070 [17:03<00:00,  1.05it/s]\n",
      "epoch 1 loss: 0.3367: 100%|██████████| 268/268 [01:43<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3590: 100%|██████████| 1070/1070 [17:02<00:00,  1.05it/s]\n",
      "epoch 2 loss: 0.3252: 100%|██████████| 268/268 [01:43<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3267: 100%|██████████| 1070/1070 [17:11<00:00,  1.04it/s]\n",
      "epoch 3 loss: 0.3188: 100%|██████████| 268/268 [01:42<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3340: 100%|██████████| 1070/1070 [17:03<00:00,  1.05it/s]\n",
      "epoch 4 loss: 0.3184: 100%|██████████| 268/268 [01:43<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3111: 100%|██████████| 1070/1070 [17:04<00:00,  1.04it/s]\n",
      "epoch 5 loss: 0.3243: 100%|██████████| 268/268 [01:44<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.2966: 100%|██████████| 1070/1070 [17:17<00:00,  1.03it/s]\n",
      "epoch 6 loss: 0.3147: 100%|██████████| 268/268 [01:43<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2599: 100%|██████████| 1070/1070 [17:11<00:00,  1.04it/s]\n",
      "epoch 7 loss: 0.3350: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2454: 100%|██████████| 1070/1070 [17:08<00:00,  1.04it/s]\n",
      "epoch 8 loss: 0.3386: 100%|██████████| 268/268 [01:43<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2227: 100%|██████████| 1070/1070 [17:03<00:00,  1.05it/s]\n",
      "epoch 9 loss: 0.3382: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8932\n",
      "Training with 2 started\n",
      "Train : 17118, Val : 4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4573: 100%|██████████| 1070/1070 [17:13<00:00,  1.04it/s]\n",
      "epoch 0 loss: 0.3687: 100%|██████████| 268/268 [01:44<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.4013: 100%|██████████| 1070/1070 [17:10<00:00,  1.04it/s]\n",
      "epoch 1 loss: 0.3642: 100%|██████████| 268/268 [01:44<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3472: 100%|██████████| 1070/1070 [17:08<00:00,  1.04it/s]\n",
      "epoch 2 loss: 0.3231: 100%|██████████| 268/268 [01:44<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3261: 100%|██████████| 1070/1070 [17:09<00:00,  1.04it/s]\n",
      "epoch 3 loss: 0.3140: 100%|██████████| 268/268 [01:44<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3277: 100%|██████████| 1070/1070 [16:54<00:00,  1.05it/s]\n",
      "epoch 4 loss: 0.3201: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3012: 100%|██████████| 1070/1070 [17:01<00:00,  1.05it/s]\n",
      "epoch 5 loss: 0.3571: 100%|██████████| 268/268 [01:43<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.2895: 100%|██████████| 1070/1070 [17:04<00:00,  1.04it/s]\n",
      "epoch 6 loss: 0.3282: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.2331: 100%|██████████| 1070/1070 [16:49<00:00,  1.06it/s]\n",
      "epoch 7 loss: 0.3376: 100%|██████████| 268/268 [01:43<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2337: 100%|██████████| 1070/1070 [17:09<00:00,  1.04it/s]\n",
      "epoch 8 loss: 0.3541: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2123: 100%|██████████| 1070/1070 [17:07<00:00,  1.04it/s]\n",
      "epoch 9 loss: 0.3444: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8878\n",
      "Training with 3 started\n",
      "Train : 17118, Val : 4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4265: 100%|██████████| 1070/1070 [17:02<00:00,  1.05it/s]\n",
      "epoch 0 loss: 0.3568: 100%|██████████| 268/268 [01:44<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.4127: 100%|██████████| 1070/1070 [17:10<00:00,  1.04it/s]\n",
      "epoch 1 loss: 0.3516: 100%|██████████| 268/268 [01:43<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3600: 100%|██████████| 1070/1070 [17:02<00:00,  1.05it/s]\n",
      "epoch 2 loss: 0.3377: 100%|██████████| 268/268 [01:43<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.3519:  84%|████████▎ | 895/1070 [14:23<02:47,  1.04it/s]"
     ]
    }
   ],
   "source": [
    "fold_num = 0\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    print('Training with {} started'.format(fold))\n",
    "    print('Train : {}, Val : {}'.format(len(trn_idx), len(val_idx)))\n",
    "    train_loader, val_loader = utils.prepare_dataloader(train,\n",
    "                                                        trn_idx,\n",
    "                                                        val_idx,\n",
    "                                                        data_root = train_img_path,\n",
    "                                                        trn_transform = trn_transform,\n",
    "                                                        val_transform = val_transform, \n",
    "                                                        bs = CFG['train_bs'], \n",
    "                                                        n_job = CFG['num_workers'])\n",
    "\n",
    "    device = torch.device(CFG['device'])\n",
    "\n",
    "    model = CassvaImgClassifier(CFG['model_arch'],\n",
    "                                train.label.nunique(),\n",
    "                                pretrained=True).to(device)\n",
    "    scaler = GradScaler()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                    lr=CFG['lr'],\n",
    "                                    weight_decay=CFG['weight_decay'])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=CFG['T_0'],\n",
    "        T_mult=1,\n",
    "        eta_min=CFG['min_lr'],\n",
    "        last_epoch=-1)\n",
    "\n",
    "    loss_tr = nn.CrossEntropyLoss().to(\n",
    "        device)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        utils.train_one_epoch(epoch,\n",
    "                            model,\n",
    "                            loss_tr,\n",
    "                            optimizer,\n",
    "                            train_loader,\n",
    "                            device,\n",
    "                            scaler,\n",
    "                            scheduler=scheduler,\n",
    "                            schd_batch_update=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            utils.valid_one_epoch(epoch,\n",
    "                                model,\n",
    "                                loss_fn,\n",
    "                                val_loader,\n",
    "                                device)\n",
    "\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            '/home/featurize/work/model_b5/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
    "\n",
    "    del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
